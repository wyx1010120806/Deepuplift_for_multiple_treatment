{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import importlib\n",
    "import basemodel\n",
    "import baseunit\n",
    "import random\n",
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import feature_select\n",
    "\n",
    "import subprocess\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sys\n",
    "import os\n",
    "import joblib\n",
    "import pickle\n",
    "import multiprocessing\n",
    "import ast\n",
    "import json\n",
    "from functools import partial\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import IterableDataset, DataLoader, get_worker_info,TensorDataset\n",
    "from functools import partial\n",
    "from feature_select import *\n",
    "from tarnet import *\n",
    "from dragonnet import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def set_seed(seed):\n",
    "        random.seed(seed)\n",
    "        np.random.seed(seed)\n",
    "        torch.manual_seed(seed)\n",
    "        torch.cuda.manual_seed_all(seed)\n",
    "        torch.backends.cudnn.deterministic = True\n",
    "        torch.backends.cudnn.benchmark = False\n",
    "set_seed(42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_shell(hdfs_ls_cmd):\n",
    "    print(hdfs_ls_cmd)\n",
    "    result = subprocess.run(hdfs_ls_cmd, shell=True, capture_output=True, text=True)     \n",
    "    if result.returncode != 0:\n",
    "        print(f\"Error listing files in HDFS: {result.stderr}\")\n",
    "    print(result)\n",
    "    print(result.returncode)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# 读取JSON文件并转换为字典\n",
    "with open('/opt/tiger/rh2_params/custom_template_vars.json', 'r') as file:\n",
    "    data = json.load(file)\n",
    "\n",
    "# 打印字典\n",
    "print(data)\n",
    "is_load_data_model_feature = int(data['is_load_data_model_feature'])\n",
    "data_path = data['data_path']\n",
    "model_path = data['model_path']\n",
    "feature_path = data['feature_path']\n",
    "discrete_feature_path = data['discrete_feature_path']\n",
    "discrete_size_path = data['discrete_size_path']\n",
    "output_path = data['output_path']\n",
    "begin = int(data['begin'])\n",
    "end = int(data['end'])\n",
    "\n",
    "print(\"is_load_data_model_feature:\", is_load_data_model_feature)\n",
    "print(\"data_path:\", data_path)\n",
    "print(\"model_path:\", model_path)\n",
    "print(\"feature_path:\", feature_path)\n",
    "print(\"discrete_feature_path:\", discrete_feature_path)\n",
    "print(\"discrete_size_path:\", discrete_size_path)\n",
    "print(\"begin:\", begin)\n",
    "print(\"end:\", end)\n",
    "model_path_list = model_path.split(',')\n",
    "\n",
    "device = torch.device(\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if is_load_data_model_feature == 1:\n",
    "    run_shell(f\"rm -r /mnt/bd/wyx08/{data_path}\")\n",
    "    run_shell(f\"hdfs dfs -get hdfs://harunasg/home/byte_ecom_product_ds_sg/{data_path} /mnt/bd/wyx08\")\n",
    "\n",
    "    for _ in model_path_list:\n",
    "        run_shell(f\"rm -r /mnt/bd/wyx08/{_}\")\n",
    "        run_shell(f\"hdfs dfs -get  hdfs://harunasg/home/byte_ecom_product_ds_sg/{_} /mnt/bd/wyx08\")\n",
    "\n",
    "    run_shell(f\"rm -r /mnt/bd/wyx08/{feature_path}\")\n",
    "    run_shell(f\"hdfs dfs -get hdfs://harunasg/home/byte_ecom_product_ds_sg/{feature_path} /mnt/bd/wyx08\")\n",
    "\n",
    "    run_shell(f\"rm -r /mnt/bd/wyx08/{discrete_feature_path}\")\n",
    "    run_shell(f\"hdfs dfs -get hdfs://harunasg/home/byte_ecom_product_ds_sg/{discrete_feature_path} /mnt/bd/wyx08\")\n",
    "\n",
    "    run_shell(f\"rm -r /mnt/bd/wyx08/{discrete_size_path}\")\n",
    "    run_shell(f\"hdfs dfs -get hdfs://harunasg/home/byte_ecom_product_ds_sg/{discrete_size_path} /mnt/bd/wyx08\")\n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "with open(f'/mnt/bd/wyx08/{feature_path}', 'rb') as f:\n",
    "    feature_list = pickle.load(f)\n",
    "print(len(feature_list))\n",
    "\n",
    "\n",
    "with open(f'/mnt/bd/wyx08/{discrete_feature_path}', 'rb') as f:\n",
    "    feature_list_discrete = pickle.load(f)\n",
    "print(len(feature_list_discrete))\n",
    "\n",
    "\n",
    "with open(f'/mnt/bd/wyx08/{discrete_size_path}', 'rb') as f:\n",
    "    discrete_size_cols = pickle.load(f)\n",
    "print(len(discrete_size_cols))\n",
    "\n",
    "model_dict = {}\n",
    "print(model_path_list)\n",
    "for path in model_path_list:\n",
    "    model = Dragonnet(input_dim=len(feature_list),discrete_size_cols=discrete_size_cols,embedding_dim=3,share_dim=64,\n",
    "                 share_hidden_dims =[512,256,256,128], share_hidden_func = torch.nn.ELU(),\n",
    "                 base_hidden_dims=[64,32,32,16],output_activation_base=torch.nn.Sigmoid(),base_hidden_func = torch.nn.ELU(),\n",
    "                 ipw_hidden_dims=[64,32,32,16],output_activation_ipw=torch.nn.Sigmoid(),ipw_hidden_func = torch.nn.ELU(),\n",
    "                 epsilons_hidden_dims=[64,32,32,16],output_activation_epsilons=torch.nn.Sigmoid(),epsilons_hidden_func = torch.nn.ELU(),\n",
    "                 task = 'classification',classi_nums=2, treatment_label_list=[0,1],model_type='Dragonnet',device=device\n",
    ")\n",
    "    # 先实例化模型\n",
    "    model.load_state_dict(torch.load(f'/mnt/bd/wyx08/{path}', map_location=device)['model_state_dict'])\n",
    "    model_dict[path.replace('.joblib','').replace('.pt','').replace('.pth','')] = model\n",
    "\n",
    "print(model_dict)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "# 定义文件夹路径\n",
    "folder_path = f'/mnt/bd/wyx08/{data_path}'\n",
    "\n",
    "# 获取文件夹下的所有文件名\n",
    "file_names = [f for f in os.listdir(folder_path) if os.path.isfile(os.path.join(folder_path, f))]\n",
    "print(len(file_names))\n",
    "res = []\n",
    "output_cols = []\n",
    "\n",
    "df = pd.read_parquet(folder_path+'/'+file_names[0])\n",
    "\n",
    "if 'user_id' in list(df.columns):\n",
    "    output_cols.append('user_id')\n",
    "\n",
    "if 'device_id' in list(df.columns):\n",
    "    output_cols.append('device_id')\n",
    "\n",
    "if 'country_code' in list(df.columns):\n",
    "    output_cols.append('country_code')\n",
    "\n",
    "if 'country' in list(df.columns):\n",
    "    output_cols.append('country')\n",
    "\n",
    "output_cols = list(set(output_cols))\n",
    "print(output_cols)\n",
    "\n",
    "# 打印所有文件名\n",
    "rank_ = 1\n",
    "print(rank_)\n",
    "import time\n",
    "for file_name in file_names:\n",
    "    if file_name.endswith('.parquet') and begin <= int(file_name.split('-')[1]) and int(file_name.split('-')[1]) <= end:\n",
    "        start_time = time.time()\n",
    "        print(rank_,file_name)\n",
    "        df_tmp = pd.read_parquet(folder_path+'/'+file_name)\n",
    "        print(df_tmp.shape)\n",
    "\n",
    "        for column in feature_list:\n",
    "            if df_tmp[column].dtype != 'float':\n",
    "                df_tmp[column] = df_tmp[column].astype('float')\n",
    "\n",
    "        for i in range(len(feature_list_discrete)):\n",
    "            df_tmp[column] = df_tmp[column].apply(lambda x: x if x >=0 and x <= discrete_size_cols[i]-2 else discrete_size_cols[i]-1)\n",
    "        \n",
    "        uplift_predictions_cols = {}\n",
    "\n",
    "        for k,model in model_dict.items():\n",
    "            df = df_tmp\n",
    "\n",
    "            X_discrete = torch.tensor(df[feature_list_discrete].values, dtype=torch.float32).to(device)\n",
    "            X_continuous = torch.tensor(df[[_ for _ in feature_list if _ not in feature_list_discrete]].values, dtype=torch.float32).to(device)\n",
    "            model.eval()\n",
    "            with torch.no_grad(): \n",
    "                uplift_predictions,y_preds,*eps = model(None, None, X_discrete=X_discrete, X_continuous=X_continuous)\n",
    "            uplift_prediction = uplift_predictions.detach().cpu().numpy()\n",
    "\n",
    "            for i in range(uplift_prediction.shape[1]):\n",
    "                if rank_ == 1:\n",
    "                    output_cols.append(str(i+1)+'_score')\n",
    "                df[str(i+1)+'_score'] = uplift_prediction[:,i]\n",
    "            print(df[output_cols])\n",
    "\n",
    "        rank_ += 1\n",
    "        print(f\"predict time: {time.time() - start_time:.4f}s\")\n",
    "\n",
    "        res.append(df[output_cols])\n",
    "        del df,df_tmp\n",
    "        import gc\n",
    "        gc.collect()\n",
    "\n",
    "final_res = pd.concat(res)\n",
    "final_res\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_shell(f\"mkdir /mnt/bd/wyx08/{output_path}\")\n",
    "final_res.to_parquet(f'/mnt/bd/wyx08/{output_path}/{begin}_{end}.parquet', engine='pyarrow', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if is_load_data_model_feature == 1:\n",
    "    run_shell(f\"hdfs dfs -rm -r hdfs://harunasg/home/byte_ecom_product_ds_sg/{output_path}\")\n",
    "run_shell(f\"hdfs dfs -mkdir hdfs://harunasg/home/byte_ecom_product_ds_sg/{output_path}/\")\n",
    "run_shell(f\"hdfs dfs -rm -r hdfs://harunasg/home/byte_ecom_product_ds_sg/{output_path}/{begin}_{end}.parquet\")\n",
    "run_shell(f\"hdfs dfs -put -f /mnt/bd/wyx08/{output_path}/{begin}_{end}.parquet hdfs://harunasg/home/byte_ecom_product_ds_sg/{output_path}/\")"
   ]
  }
 ],
 "metadata": {
  "fileId": "beb3992b-677d-47b6-8ae9-c1af57f41da3",
  "filePath": "/mlx_devbox/users/wangyuxin.huoshan/playground/deeplift/main.ipynb",
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "pythonjvsc74a57bd03dd32d9f94238ec8b0e4f79eabc9bcad10ffae3232487ad50a9b3a08094f8c66"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
